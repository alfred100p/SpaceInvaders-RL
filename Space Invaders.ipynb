{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86e081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c95f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('SpaceInvaders-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24163d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space #has 6 discrete actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55db859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n",
      "Score: 240.0\n",
      "Episode: 2\n",
      "Score: 30.0\n",
      "Episode: 3\n",
      "Score: 30.0\n",
      "Episode: 4\n",
      "Score: 80.0\n",
      "Episode: 5\n",
      "Score: 120.0\n",
      "Episode: 6\n",
      "Score: 120.0\n",
      "Episode: 7\n",
      "Score: 155.0\n",
      "Episode: 8\n",
      "Score: 105.0\n",
      "Episode: 9\n",
      "Score: 50.0\n"
     ]
    }
   ],
   "source": [
    "episodes=10\n",
    "\n",
    "for episode in range(1,episodes):\n",
    "    state=env.reset() #resetting env at start\n",
    "    done=False #done flag to tell agent has completed\n",
    "    score=0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        state,reward,done,info=env.step(env.action_space.sample())#does random action in action space\n",
    "        score+=reward\n",
    "    print('Episode: {}\\nScore: {}'.format(episode,score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129e3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1b55b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(height, width, channels, actions):\n",
    "    model= Sequential()#sequential layer\n",
    "    model.add(Conv2D(32,(8,8),strides=(4,4), activation='relu', input_shape=(3, height, width,channels)))#32 no of filters 8 is filter size and 4 is stride width\n",
    "    model.add(Conv2D(64,(4,4), strides=(2,2), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(actions,activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf4e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width,channels=env.observation_space.shape\n",
    "actions=env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a24504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model(height,width,channels,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f098ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c27605a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model,actions):\n",
    "    policy=LinearAnnealedPolicy(EpsGreedyQPolicy(),attr='eps',value_max=1, value_min=.1,value_test=.2, nb_steps=10000)\n",
    "    memory=SequentialMemory(limit=2000,window_length=3)\n",
    "    dqn=DQNAgent(model=model, memory=memory,policy=policy,enable_dueling_network=True,dueling_type='avg',nb_actions=actions, nb_steps_warmup=1000)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c6ff3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model \n",
    "#uncomment and run if you get memory error in below cell \n",
    "#go back to creating model after running this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4df8a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn=build_agent(model,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e67c40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.compile(Adam(lr=0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23f27083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPossible optimization:\\n* add more conv layers\\n* add more dense layers\\n* increase dataset size by increasing sequential memory limit(currently 2000)\\n* Change greedy max and min\\n* more training\\n* change learning rate\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Possible optimization:\n",
    "* add more conv layers\n",
    "* add more dense layers\n",
    "* increase dataset size by increasing sequential memory limit(currently 2000)\n",
    "* Change greedy max and min\n",
    "* more training\n",
    "* change learning rate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227746f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 40000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From c:\\users\\alela\\anaconda3\\envs\\practicalrl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      " 1078/10000 [==>...........................] - ETA: 12:35 - reward: 0.1438"
     ]
    }
   ],
   "source": [
    "dqn.fit(env,nb_steps=40000,visualize=False,verbose=1)#visualization decreases training speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8967132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n",
      "WARNING:tensorflow:From c:\\users\\alela\\anaconda3\\envs\\practicalrl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "Episode 1: reward: 90.000, steps: 792\n",
      "Episode 2: reward: 135.000, steps: 749\n",
      "Episode 3: reward: 105.000, steps: 649\n",
      "Episode 4: reward: 195.000, steps: 855\n",
      "Episode 5: reward: 110.000, steps: 618\n",
      "Episode 6: reward: 160.000, steps: 747\n",
      "Episode 7: reward: 230.000, steps: 944\n",
      "Episode 8: reward: 535.000, steps: 1227\n",
      "Episode 9: reward: 110.000, steps: 723\n",
      "Episode 10: reward: 155.000, steps: 601\n",
      "182.5\n"
     ]
    }
   ],
   "source": [
    "scores=dqn.test(env,nb_episodes=10,visualize=True)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.save_weights('models/dqn001.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b515d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.load_weights('models/dqn.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f08f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
