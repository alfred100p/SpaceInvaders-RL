{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d13cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aca0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "env= gym.make('SpaceInvaders-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a37cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space #has 6 discrete actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d6d07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1\n",
      "Score: 110.0\n",
      "Episode: 2\n",
      "Score: 105.0\n",
      "Episode: 3\n",
      "Score: 120.0\n",
      "Episode: 4\n",
      "Score: 30.0\n",
      "Episode: 5\n",
      "Score: 115.0\n",
      "Episode: 6\n",
      "Score: 105.0\n",
      "Episode: 7\n",
      "Score: 45.0\n",
      "Episode: 8\n",
      "Score: 135.0\n",
      "Episode: 9\n",
      "Score: 215.0\n"
     ]
    }
   ],
   "source": [
    "episodes=10\n",
    "\n",
    "for episode in range(1,episodes):\n",
    "    state=env.reset() #resetting env at start\n",
    "    done=False #done flag to tell agent has completed\n",
    "    score=0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        state,reward,done,info=env.step(env.action_space.sample())#does random action in action space\n",
    "        score+=reward\n",
    "    print('Episode: {}\\nScore: {}'.format(episode,score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb324808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a8ef9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(height, width, channels, actions):\n",
    "    model= Sequential()#sequential layer\n",
    "    model.add(Conv2D(32,(8,8),strides=(4,4), activation='relu', input_shape=(3, height, width,channels)))#32 no of filters 8 is filter size and 4 is stride width\n",
    "    model.add(Conv2D(64,(4,4), strides=(2,2), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(actions,activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52262099",
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width,channels=env.observation_space.shape\n",
    "actions=env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44197153",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model #for rebuilding agent to prevent memroy errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8a06a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model(height,width,channels,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84fb13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc303835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent(model,actions):\n",
    "    policy=LinearAnnealedPolicy(EpsGreedyQPolicy(),attr='eps',value_max=1, value_min=.1,value_test=.2, nb_steps=10000)\n",
    "    memory=SequentialMemory(limit=2000,window_length=3)\n",
    "    dqn=DQNAgent(model=model, memory=memory,policy=policy,enable_dueling_network=True,dueling_type='avg',nb_actions=actions, nb_steps_warmup=1000)\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22688045",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn=build_agent(model,actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba4714d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.compile(Adam(lr=0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Possible optimization:\n",
    "* add more conv layers\n",
    "* add more dense layers\n",
    "* increase dataset size by increasing sequential memory limit(currently 2000)\n",
    "* Change greedy max and min\n",
    "* more training\n",
    "* change learning rate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82356fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 40000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "WARNING:tensorflow:From c:\\users\\alela\\anaconda3\\envs\\practicalrl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      " 1700/10000 [====>.........................] - ETA: 49:18 - reward: 0.1794"
     ]
    }
   ],
   "source": [
    "dqn.fit(env,nb_steps=40000,visualize=False,verbose=1)#visualization decreases training speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b5f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=dqn.test(env,nb_episodes=10,visualize=True)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
